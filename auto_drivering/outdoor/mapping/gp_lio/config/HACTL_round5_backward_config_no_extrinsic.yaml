%YAML:1.0

#common parameters
output_path: "/home/wchen/Projects/Code/catkin_ws/src/gp_lio/result/"

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
  # 1   Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.
  #If you choose 0 or 1, you should write down the following matrix.

#Rotation from camera frame to imu frame, imu^R_cam
extrinsicRotation: !!opencv-matrix
  rows: 3
  cols: 3
  dt: d
  data: [1, 0, 0,
           0, 1, 0,
           0, 0, 1]
#Translation from camera frame to imu frame, imu^T_cam
extrinsicTranslation: !!opencv-matrix
  rows: 3
  cols: 1
  dt: d
  data: [0.0, 0.0, 0.0]

#feature traker paprameters
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image

#optimization parameters
max_solver_time: 0.15  # max solver itration time (s), to guarantee real time
max_num_iterations: 50   # max solver itrations, to guarantee real time
ceres_solver_threads: 4

  #imu parameters       The more accurate parameters you provide, the better performance
acc_n: 0.2          # accelerometer measurement noise standard deviation. #0.2
gyr_n: 0.04         # gyroscope measurement noise standard deviation.     #0.05
acc_w: 0.0002         # accelerometer bias random work noise standard deviation.  #0.02
gyr_w: 2.0e-5       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.81007     # gravity magnitude

#unsynchronization parameters
estimate_td: 0                      # online estimate time offset between camera and imu
td: 0.0                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#visualization parameters
visualize_imu_forward: 0        # output imu forward propogation to achieve low latency and high frequence results
visualize_camera_size: 0.4      # size of camera marker in RVIZ

# sliding window
fixed_size: 1  #>=1
keyframe_time_diff: 0.3
keyframe_distance: 2
keyframe_rotation: 15

#lidar parameters
ground_scan_ind: 7
ground_angle_th: 10
ground_feature_resolution: 5
edge_feature_th: 0.1
surf_feature_th: 0.1
nearest_feature_search_sq_dist: 2.0
use_edge_factor: 1
use_surf_factor: 0
use_ground_factor: 1
use_imu_factor: 1
use_auto_diff: 1
edge_factor_weight: 1
surf_factor_weight: 1
save_feature_tmp_result: 1
segment_valid_size: 20

use_plane_factor: 1
plane_factor_weight: 1
plane_window_rows: 3
plane_window_cols: 20
plane_window_rate: 0.6
plane_region_distance_threshold: 0.5
plane_fitting_mse: 0.001
plane_fitting_distance_threshold: 0.05
plane_point_size: 20
point_measurement_noise: 0.03
plane_associated_angle: 5
plane_associated_overlapping_rate: 0.5
plane_cluster_center_distance: 0.3

# loop closure detection (OpenSeqSLAM2.0)
#  search
d_s: 10
v_min: 0.8
v_max: 1.2
# matching
matching_window: 5
matching_u_rate: 1.4
matching_threshold: 0.15
matching_min_idx: 50
icp_fitness_score: 0.3

# pose graph
std_x: 1e-6
std_y: 1e-6
std_z: 1e-6
std_r: 1e-8
std_p: 1e-8
std_yaw: 1e-6